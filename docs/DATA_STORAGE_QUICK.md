# Data Storage - Quick Reference

## ğŸ“Š How Data Gets Stored in OrgMind

### Simple Answer
Your data flows through 4 layers:
1. **CSV files** (you can edit)
2. **Pickle file** (compiled graph)
3. **RAM** (active processing)
4. **JSON** (sent to browser)

---

## Visual Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. SOURCE DATA (Editable)                                  â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                                 â”‚
â”‚  ğŸ“„ company_emails.csv (10 KB)                              â”‚
â”‚     â”œâ”€â”€ 20 emails                                            â”‚
â”‚     â”œâ”€â”€ Human readable                                       â”‚
â”‚     â””â”€â”€ Easy to edit in Excel/text editor                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ python scripts/load_real_data.py
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. COMPILED GRAPH (Persistent)                             â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                             â”‚
â”‚  ğŸ’¾ knowledge_graph.pkl (4.7 KB)                            â”‚
â”‚     â”œâ”€â”€ NetworkX DiGraph (binary)                           â”‚
â”‚     â”œâ”€â”€ 71 nodes + 7 edges                                  â”‚
â”‚     â””â”€â”€ NOT human readable                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Backend starts, loads .pkl
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. IN-MEMORY GRAPH (Active)                                â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                              â”‚
â”‚  âš¡ RAM (~1 MB)                                              â”‚
â”‚     â”œâ”€â”€ graph_builder: GraphBuilder                         â”‚
â”‚     â”œâ”€â”€ coordinator: Coordinator (agents)                   â”‚
â”‚     â”œâ”€â”€ Fast queries (microseconds)                         â”‚
â”‚     â””â”€â”€ Lost on restart unless saved                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ API request
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. API RESPONSE (Frontend)                                 â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                               â”‚
â”‚  ğŸŒ JSON (~50 KB)                                           â”‚
â”‚     â”œâ”€â”€ {nodes: [...], edges: [...]}                       â”‚
â”‚     â”œâ”€â”€ Sent to browser                                     â”‚
â”‚     â””â”€â”€ Rendered as graph visualization                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Storage Details

### ğŸ“„ Layer 1: CSV (Source)
**File**: `backend/data/raw/company_emails.csv`

```csv
id,date,sender,to,cc,subject,body
1,2024-01-15,john.smith@company.com,team@company.com,...
```

**Technology**: Plain text CSV  
**Size**: ~10 KB  
**Editable**: âœ… Yes, with any text editor  
**Persistent**: âœ… Yes, committed to git

---

### ğŸ’¾ Layer 2: Pickle (Compiled)
**File**: `backend/data/processed/knowledge_graph.pkl`

**Technology**: Python Pickle + NetworkX  
**Size**: 4.7 KB  
**Format**: Binary (not human-readable)  

**What's Inside**:
```python
NetworkX DiGraph
â”œâ”€â”€ Nodes: {
â”‚     "Susan Williams": {label: "Susan Williams", type: "person"},
â”‚     "decision_0": {label: "Product Launch...", type: "decision"},
â”‚     ...
â”‚   }
â””â”€â”€ Edges: {
      ("decision_0", "John Smith"): {relation_type: "made_by"},
      ...
    }
```

**How It's Created**:
```python
# graph_builder.py
def save(self, path):
    with open(path, "wb") as f:
        pickle.dump(self._graph, f)  # Serialize NetworkX graph

def load(cls, path):
    with open(path, "rb") as f:
        graph = pickle.load(f)  # Deserialize
    return GraphBuilder(graph)
```

**Pros**: Fast to load, preserves graph structure  
**Cons**: Binary format, Python-specific

---

### âš¡ Layer 3: RAM (Active Processing)
**Location**: Backend process memory

**Main Objects**:
```python
# main.py (shared state)
graph_builder = GraphBuilder()  # The live graph
coordinator = Coordinator()     # AI agents
app.state.graph_cache = {}      # JSON cache
```

**Technology**: NetworkX DiGraph in Python memory  
**Size**: ~1 MB  
**Speed**: Microseconds  
**Persistent**: âŒ No (lost on restart)

**Operations**:
```python
# Add a new person (happens in RAM)
graph_builder.add_entity("Jane Doe", "Jane Doe", {"type": "person"})

# Add a connection (happens in RAM)
graph_builder.add_relation("Jane Doe", "Project Alpha", "works_on")

# Query (instant, from RAM)
nodes = graph_builder.get_nodes()
edges = graph_builder.get_edges()
```

---

### ğŸŒ Layer 4: JSON (API Response)
**Location**: HTTP response to frontend

**Format**:
```json
{
  "nodes": [
    {"id": "Susan Williams", "label": "Susan Williams", "type": "person"},
    {"id": "decision_0", "label": "Product Launch", "type": "decision"}
  ],
  "edges": [
    {"source": "decision_0", "target": "John Smith", "relation_type": "made_by"}
  ],
  "metadata": {
    "node_count": 72,
    "edge_count": 7,
    "version": 0
  }
}
```

**Created by**:
```python
# graph_export.py
exporter = GraphExporter(graph_builder)
json_data = exporter.to_dict()
```

**Sent to**: Frontend React app  
**Used for**: Visualization with ReactFlow

---

## Key Files

```
backend/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ company_emails.csv           â† YOU EDIT THIS
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ knowledge_graph.pkl          â† COMPILED OUTPUT
â”‚
â”œâ”€â”€ knowledge_graph/
â”‚   â””â”€â”€ graph_builder.py                 â† STORAGE LOGIC
â”‚       â€¢ save() â†’ pickle.dump()
â”‚       â€¢ load() â†’ pickle.load()
â”‚       â€¢ NetworkX DiGraph
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ load_real_data.py                â† CSV â†’ PKL CONVERTER
â”‚       â€¢ Reads CSV
â”‚       â€¢ Builds graph
â”‚       â€¢ Saves as pickle
â”‚
â””â”€â”€ main.py                              â† BACKEND SERVER
    â€¢ Loads .pkl on startup
    â€¢ Keeps graph in RAM
    â€¢ Serves JSON via API
```

---

## Storage Technologies

### NetworkX
**What**: Python library for graphs/networks  
**Version**: 3.6.1  
**Why**: Industry standard for graph algorithms

**Core Structure**:
```python
import networkx as nx

# Create directed graph
graph = nx.DiGraph()

# Add nodes with attributes
graph.add_node("John", label="John Smith", type="person")

# Add edges with attributes  
graph.add_edge("John", "Project A", relation_type="works_on")

# Query
graph.nodes(data=True)   # All nodes with attributes
graph.edges(data=True)   # All edges with attributes
graph.neighbors("John")  # Connected nodes
```

**Why DirectedGraph (DiGraph)?**
- Relationships have direction: `A â†’ B` â‰  `B â†’ A`
- Example: "John **made** decision_1" (not: decision_1 made John)

---

### Python Pickle
**What**: Python's built-in serialization format  
**Format**: Binary

**How It Works**:
```python
import pickle

# Save
with open('graph.pkl', 'wb') as f:
    pickle.dump(networkx_graph, f)

# Load
with open('graph.pkl', 'rb') as f:
    graph = pickle.load(f)
```

**Pros**:
- âœ… Fast serialize/deserialize
- âœ… Preserves Python objects exactly
- âœ… Built-in (no extra dependencies)

**Cons**:
- âŒ Binary (not human-readable)
- âŒ Python-only (not portable to other languages)
- âŒ Security risk with untrusted files

---

## Data Lifecycle

### Startup Sequence
```
1. Backend starts
   â†“
2. Check: does knowledge_graph.pkl exist?
   â†“
3. YES â†’ Load pickle â†’ Deserialize â†’ Store in RAM
   NO  â†’ Generate mock data â†’ Store in RAM
   â†“
4. Export to JSON cache
   â†“
5. Server ready (graph in memory)
```

### Adding New Data
```
1. Edit company_emails.csv
   â†“
2. Run: python scripts/load_real_data.py
   â†“
3. Script reads CSV, builds graph, saves .pkl
   â†“
4. Restart backend
   â†“
5. Backend loads new .pkl
   â†“
6. New data visible in UI
```

### Runtime Changes
```
User submits query â†’ POST /query
   â†“
Coordinator processes (modifies RAM graph)
   â†“
Changes exist in RAM only
   â†“
NOT saved to .pkl (unless explicitly called)
   â†“
Lost on restart
```

---

## Persistence Strategy

### âœ… What Gets Saved
- Source CSV (manual edits)
- Compiled .pkl (from script)

### âŒ What Doesn't Get Saved
- Runtime graph changes (API modifications)
- Agent reasoning history
- Query results
- Demo scenario changes

### ğŸ”„ To Persist Runtime Changes
Currently NO auto-save. To implement:

```python
# Option 1: Save after every change
@app.post("/process")
async def process_info(info):
    result = coordinator.process(info)
    graph_builder.save("data/processed/knowledge_graph.pkl")
    return result

# Option 2: Manual save endpoint
@app.post("/graph/save")
async def save_graph():
    graph_builder.save("data/processed/knowledge_graph.pkl")
    return {"status": "saved"}

# Option 3: Periodic auto-save (background task)
@app.on_event("startup")
async def periodic_save():
    while True:
        await asyncio.sleep(300)  # Every 5 minutes
        graph_builder.save("data/processed/knowledge_graph.pkl")
```

---

## Advantages of This Architecture

### âœ… Pros
1. **Fast Queries**: All data in RAM, microsecond access
2. **Simple**: No database setup needed
3. **Portable**: Single .pkl file
4. **Graph Algorithms**: NetworkX has 100+ built-in algorithms
5. **Flexible**: Easy to modify graph structure

### âš ï¸ Cons
1. **Not Persistent**: Runtime changes lost
2. **Single Process**: Can't scale to multiple servers
3. **No Transactions**: No rollback on errors
4. **RAM Limited**: Graph size limited by memory
5. **Binary Format**: Can't inspect .pkl directly

---

## Future Improvements

### Recommended Next Steps

1. **Add Database** (PostgreSQL)
   - Persistent storage
   - Concurrent access
   - Transactions
   
2. **Add Auto-Save**
   - Save after modifications
   - Versioned backups
   
3. **Add Vector Store** (pgvector)
   - Semantic search
   - Similar entities
   
4. **Export Options**
   - GraphML for Neo4j
   - JSON for portability
   
5. **Add Backup System**
   - Daily snapshots
   - Version control

---

## Quick Commands

```bash
# View source data
cat backend/data/raw/company_emails.csv

# Rebuild graph from CSV
cd backend
python scripts/load_real_data.py

# Inspect pickle
python3 << EOF
import pickle
with open('data/processed/knowledge_graph.pkl', 'rb') as f:
    graph = pickle.load(f)
    print(f"Nodes: {graph.number_of_nodes()}")
    print(f"Edges: {graph.number_of_edges()}")
EOF

# Check backend API
curl http://localhost:8000/graph | python -m json.tool

# Check graph stats
curl http://localhost:8000/health | python -m json.tool
```

---

## Summary

**Storage Stack**:
- **CSV** (source) â†’ **Pickle** (compiled) â†’ **RAM** (active) â†’ **JSON** (display)

**Key Insight**: The graph lives in memory (RAM) for speed, backed by a pickle file for persistence. Changes in RAM are NOT auto-saved.

**Main Technology**: NetworkX DiGraph serialized with Python Pickle

**File Size**: 4.7 KB (very compact!)

---

**Questions?** Check `DATA_STORAGE.md` for the complete technical documentation.
